{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd32be1e-5c4c-42b7-8363-097dcec560a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scraper_models\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import sys\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ab3e36-5f99-431d-8fa8-39cf82382316",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a72270c-fba7-4645-9035-49ee736fa217",
   "metadata": {},
   "source": [
    "# extract info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bdb79f-6e17-4784-82aa-c797dca8ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_profile(raw_dict):\n",
    "    \"\"\"extract a LinkedIn profile info into a dictionary\"\"\"\n",
    "    # information to extract from given profile\n",
    "    keys = [\n",
    "        \"objectUrn\",\n",
    "        \"flagshipProfileUrl\",\n",
    "        \"fullName\",\n",
    "        \"headline\",\n",
    "        \"summary\",\n",
    "        \"location\",\n",
    "        \"industry\",\n",
    "    ]\n",
    "\n",
    "    # store info in new dictionary (value is None if key is not found)\n",
    "    profile_dict = {key: (raw_dict[key] if key in raw_dict else None) for key in keys}\n",
    "\n",
    "    # grab the integer part in LinkedIn ID\n",
    "    try:\n",
    "        profile_dict[\"objectUrn\"] = int(\n",
    "            re.findall(r\"\\d+\", profile_dict[\"objectUrn\"])[0]\n",
    "        )\n",
    "    except:\n",
    "        profile_dict[\"objectUrn\"] = None\n",
    "\n",
    "    # return as dictionary\n",
    "    return profile_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b7716e-f0de-41c8-b441-9acef522839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_profile_experiences(raw_dict):\n",
    "    \"\"\"extract a user's experiences into a list of dictionaires\"\"\"\n",
    "\n",
    "    # information to extract from given experience\n",
    "    keys = [\n",
    "        \"companyName\",\n",
    "        \"title\",\n",
    "        \"location\",\n",
    "        \"startedOn\",\n",
    "        \"endedOn\",\n",
    "        \"description\",\n",
    "        \"current\",\n",
    "        \"new\",\n",
    "    ]\n",
    "\n",
    "    # initialize empty list to collect exp_dict\n",
    "    exp_list = []\n",
    "\n",
    "    # loop through each experience\n",
    "    for exp in raw_dict[\"positions\"]:\n",
    "        exp_dict = {key: (exp[key] if key in exp else None) for key in keys}\n",
    "        if exp_dict[\"startedOn\"]:\n",
    "            year = exp_dict[\"startedOn\"][\"year\"]\n",
    "            month = (\n",
    "                exp_dict[\"startedOn\"][\"month\"]\n",
    "                if \"month\" in exp_dict[\"startedOn\"]\n",
    "                else 1\n",
    "            )  # default to January\n",
    "            exp_dict[\"startedOn\"] = parse(str(year) + \"-\" + str(month))\n",
    "        if exp_dict[\"endedOn\"]:\n",
    "            year = exp_dict[\"endedOn\"][\"year\"]\n",
    "            month = (\n",
    "                exp_dict[\"endedOn\"][\"month\"] if \"month\" in exp_dict[\"endedOn\"] else 1\n",
    "            )  # default to January\n",
    "            exp_dict[\"endedOn\"] = parse(str(year) + \"-\" + str(month))\n",
    "        # append dictionary to list\n",
    "        exp_list.append(exp_dict)\n",
    "\n",
    "    # return a list of experiences\n",
    "    return exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b983d336-e80f-44fa-b34c-a7fac0f14ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_profile_institutions(raw_dict):\n",
    "    \"\"\"extract a user's educations info a list of dictionaries\"\"\"\n",
    "\n",
    "    # information to extract from given experience\n",
    "    keys = [\"degree\", \"schoolName\", \"school\", \"startedOn\", \"endedOn\", \"fieldsOfStudy\"]\n",
    "\n",
    "    # initialize empty list to collect edu_dict\n",
    "    edu_list = []\n",
    "\n",
    "    # loop through each education\n",
    "    for edu in raw_dict[\"educations\"]:\n",
    "        # grab values picked out by each of the 6 keys\n",
    "        edu_dict = {key: (edu[key] if key in edu else None) for key in keys}\n",
    "        # rename \"school\" as \"school_id\" and only keep the integer part\n",
    "        edu_dict[\"school_id\"] = edu_dict.pop(\"school\")\n",
    "        try:\n",
    "            edu_dict[\"school_id\"] = int(re.findall(r\"\\d+\", edu_dict[\"school_id\"])[0])\n",
    "        except:\n",
    "            edu_dict[\"school_id\"] = None\n",
    "        # find start_date (month defaults to September)\n",
    "        if edu_dict[\"startedOn\"]:\n",
    "            year = edu_dict[\"startedOn\"][\"year\"]\n",
    "            month = (\n",
    "                9 if edu_dict[\"startedOn\"][\"year\"] < edu_dict[\"endedOn\"][\"year\"] else 1\n",
    "            )\n",
    "            edu_dict[\"startedOn\"] = parse(str(year) + \"-\" + str(month))\n",
    "        # find end_date (month defaults to June)\n",
    "        if edu_dict[\"endedOn\"]:\n",
    "            year = edu_dict[\"endedOn\"][\"year\"]\n",
    "            month = (\n",
    "                6 if edu_dict[\"startedOn\"].year < edu_dict[\"endedOn\"][\"year\"] else 12\n",
    "            )\n",
    "            edu_dict[\"endedOn\"] = parse(str(year) + \"-\" + str(month))\n",
    "\n",
    "        # if fieldOfStudy exists\n",
    "        if edu_dict[\"fieldsOfStudy\"]:\n",
    "            # split each field into a separate education\n",
    "            for field in edu_dict[\"fieldsOfStudy\"][0].split(\",\"):\n",
    "                # create a deep copy of original dictionary\n",
    "                new_edu_dict = copy.deepcopy(edu_dict)\n",
    "                # change fieldsOfStudy to a single field\n",
    "                new_edu_dict[\"fieldsOfStudy\"] = field.strip()\n",
    "                # append dictionary to list\n",
    "                edu_list.append(new_edu_dict)\n",
    "\n",
    "    # return a list of educations\n",
    "    return edu_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93c0fa-f956-4ce0-8da7-c3131e2a3938",
   "metadata": {},
   "source": [
    "# insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43b9217-f178-4735-b56c-378278f05c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = scraper_models.get_logging()\n",
    "gas = scraper_models.get_analytics_session()\n",
    "s = scraper_models.get_prod_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852b1cf2-c077-4468-bc8a-5231f7dfc3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all LinkedIn data\n",
    "ld = scraper_models.get_scraped_data_by_id(gas, scraper_models.lsn_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba72824-6dc8-47e8-b1dc-5cc42b750c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each LinkedIn profile\n",
    "for i, link in enumerate(ld):\n",
    "    # get JSON content\n",
    "    ljson = link.value\n",
    "    # load into a dictionary\n",
    "    try:\n",
    "        raw_dict = json.loads(ljson)\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Incorrect json formatting: {e}\")\n",
    "        scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "        sys.exit()\n",
    "\n",
    "    # extract profile info into a dictionary\n",
    "    profile = extract_profile(raw_dict)\n",
    "\n",
    "    # create a Profile object\n",
    "    p = scraper_models.Profile(\n",
    "        created_at=datetime.utcnow(),\n",
    "        updated_at=datetime.utcnow(),\n",
    "        user_id=None,\n",
    "        url=profile.get(\"flagshipProfileUrl\"),\n",
    "        name=profile.get(\"fullName\"),\n",
    "        headline=profile.get(\"headline\"),\n",
    "        summary=profile.get(\"summary\"),\n",
    "        location=profile.get(\"location\"),\n",
    "        attribution=\"linkedin\",\n",
    "        attribution_id=link.attribution_id,\n",
    "        industry=profile.get(\"industry\"),\n",
    "        linkedin_id=profile.get(\"objectUrn\"),\n",
    "    )\n",
    "    # commit to production database\n",
    "    try:\n",
    "        s.add(p)\n",
    "        s.commit()\n",
    "    except Exception as e:\n",
    "        s.rollback()\n",
    "        logger.error(f\"Profiles insertion failed on linkedin etl: {e}\")\n",
    "        scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "        sys.exit()\n",
    "\n",
    "    # expract profile experiences\n",
    "    profile_experiences = extract_profile_experiences(raw_dict)\n",
    "\n",
    "    # first, insert experiences into the roles table\n",
    "    roles = []\n",
    "\n",
    "    # create a Role object for each experience\n",
    "    for pe in profile_experiences:\n",
    "        roles.append(\n",
    "            scraper_models.Role(\n",
    "                created_at=datetime.utcnow(),\n",
    "                updated_at=datetime.utcnow(),\n",
    "                user_submitted_company=pe.get(\"companyName\"),\n",
    "                user_submitted_title=pe.get(\"title\"),\n",
    "                user_submitted_location=pe.get(\"location\"),\n",
    "                company_id=None,\n",
    "                city_id=None,\n",
    "                seniority_id=None,\n",
    "                position_title_id=None,\n",
    "            )\n",
    "        )\n",
    "    try:\n",
    "        s.bulk_save_objects(roles, return_defaults=True)\n",
    "        s.commit()\n",
    "    except Exception as e:\n",
    "        s.rollback()\n",
    "        logger.error(f\"Roles insertion failed on linkedin etl: {e}\")\n",
    "        scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "        sys.exit()\n",
    "\n",
    "    # then, insert experiences into profile_experiences table\n",
    "    db_pe = []\n",
    "\n",
    "    # create a ProfileExperience object for each experience\n",
    "    for pe, role in zip(profile_experiences, roles):\n",
    "        db_pe.append(\n",
    "            scraper_models.ProfileExperience(\n",
    "                profile_id=p.id,\n",
    "                created_at=datetime.utcnow(),\n",
    "                updated_at=datetime.utcnow(),\n",
    "                role_id=role.id,\n",
    "                description=pe.get(\"description\"),\n",
    "                from_date=pe.get(\"startedOn\"),\n",
    "                to_date=pe.get(\"endedOn\"),\n",
    "                most_recent=pe.get(\"new\"),\n",
    "                current_role=pe.get(\"current\"),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        s.bulk_save_objects(db_pe)\n",
    "        s.commit()\n",
    "    except Exception as e:\n",
    "        s.rollback()\n",
    "        logger.error(f\"Experiences insertion failed on linkedin etl: {e}\")\n",
    "        scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "        sys.exit()\n",
    "\n",
    "    # extract profile_institutions\n",
    "    profile_institutions = extract_profile_institutions(raw_dict)\n",
    "\n",
    "    # insert into profile_institutions table\n",
    "    db_pi = []\n",
    "\n",
    "    # loop through each insititution\n",
    "    for pi in profile_institutions:\n",
    "\n",
    "        # edu_id defaults to None\n",
    "        edu_id = None\n",
    "\n",
    "        # check if records by this linkedin_institution_id exists\n",
    "        ei = scraper_models.get_education_from_linkedin_id(s, pi.get(\"school_id\"))\n",
    "\n",
    "        # if not, create an EducationInstitution object\n",
    "        if ei is None:\n",
    "            new_ei = scraper_models.EducationInstitution(\n",
    "                created_at=datetime.utcnow(),\n",
    "                updated_at=datetime.utcnow(),\n",
    "                name=pi.get(\"schoolName\") if pi.get(\"schoolName\") else \"\",\n",
    "                linkedin_edu_id=pi.get(\"school_id\"),\n",
    "            )\n",
    "            # commit to production database\n",
    "            try:\n",
    "                s.add(new_ei)\n",
    "                s.commit()\n",
    "            except Exception as e:\n",
    "                s.rollback()\n",
    "                logger.error(f\"Institutions insertion failed on linkedin etl: {e}\")\n",
    "                scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "                sys.exit()\n",
    "            # use newly created id\n",
    "            edu_id = new_ei.id\n",
    "        # if schoolName in database is empty but has a value in profile\n",
    "        elif ei.name == \"\" and pi.get(\"schoolName\") != \"\":\n",
    "            # we can use the id\n",
    "            edu_id = ei.id\n",
    "            # but update with name found in profile\n",
    "            ei.name = pi.get(\"schoolName\")\n",
    "            # commit to database\n",
    "            try:\n",
    "                s.commit()\n",
    "            except Exception as e:\n",
    "                s.rollback()\n",
    "                logger.error(f\"School name insertion failed on linkedin etl: {e}\")\n",
    "                scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "                sys.exit()\n",
    "        # if id exists, use it directly\n",
    "        else:\n",
    "            # use existing id\n",
    "            edu_id = ei.id\n",
    "\n",
    "        db_pi.append(\n",
    "            scraper_models.ProfileEducation(\n",
    "                profile_id=p.id,\n",
    "                created_at=datetime.utcnow(),\n",
    "                updated_at=datetime.utcnow(),\n",
    "                institution_id=edu_id,\n",
    "                degree=pi.get(\"degree\"),\n",
    "                field=pi.get(\"fieldsOfStudy\"),\n",
    "                from_date=pi.get(\"startedOn\"),\n",
    "                to_date=pi.get(\"endedOn\"),\n",
    "            )\n",
    "        )\n",
    "        try:\n",
    "            s.bulk_save_objects(db_pi)\n",
    "            s.commit()\n",
    "        except Exception as e:\n",
    "            s.rollback()\n",
    "            logger.error(f\"Educations insertion failed on linkedin etl: {e}\")\n",
    "            scraper_models.dump_analytics(gas, i, False, scraper_models.lsn_job_id)\n",
    "            sys.exit()\n",
    "\n",
    "try:\n",
    "    for link in ld:\n",
    "        link.migrated = True\n",
    "    gas.bulk_update_mappings(scraper_models.RawData, [{0: 1}] * len(ld))\n",
    "    gas.commit()\n",
    "except Exception as e:\n",
    "    gas.rollback()\n",
    "    logger.error(f\"Migration of successful insert failed: {e}\")\n",
    "    scraper_models.dump_analytics(gas, len(ld), False, scraper_models.lsn_job_id)\n",
    "    sys.exit()\n",
    "\n",
    "scraper_models.dump_analytics(gas, len(ld), True, scraper_models.lsn_job_id)\n",
    "gas.close()\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83efa7c-5647-4aed-a62f-17ac431e00f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
